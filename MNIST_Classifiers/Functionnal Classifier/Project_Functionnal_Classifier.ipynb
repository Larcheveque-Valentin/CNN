{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 15 14:49:58 2022\n",
    "\n",
    "@author: Sidi Wu and Cédric Beaulac\n",
    "\n",
    "Functional autoencoder implementation\n",
    "\"\"\"\n",
    "\n",
    "# Import modules\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "# import skfda as fda\n",
    "# from skfda import representation as representation\n",
    "# from skfda.exploratory.visualization import FPCAPlot\n",
    "# # from skfda.exploratory.visualization import FPCAPlot\n",
    "# # from skfda.preprocessing.dim_reduction import FPCA\n",
    "# # from skfda.representation.basis import BSpline, Fourier, Monomial\n",
    "import scipy\n",
    "from scipy.interpolate import BSpline\n",
    "import os\n",
    "import ignite\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from random import seed\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from statistics import stdev\n",
    "import skfda\n",
    "\n",
    "import skfda\n",
    "from skfda import FDataGrid as fd\n",
    "from skfda.representation.basis import BSpline as B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Importation des données sous forme FDA\n",
    "\n",
    "ElNino_OISST_region_1and2=skfda.datasets.fetch_cran(\"ElNino_OISST_region_1and2\",\"rainbow\")\n",
    "ElNino_OISST_region_3=skfda.datasets.fetch_cran(\"ElNino_OISST_region_3\",\"rainbow\")\n",
    "ElNino_OISST_region_4=skfda.datasets.fetch_cran(\"ElNino_OISST_region_4\",\"rainbow\")\n",
    "ElNino_OISST_region_3and4=skfda.datasets.fetch_cran(\"ElNino_OISST_region_3and4\",\"rainbow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElNino_OISST_region_1and2_y=ElNino_OISST_region_1and2['ElNino_OISST_region_1and2']['y'].to_numpy()\n",
    "ElNino_OISST_region_1and2_x=ElNino_OISST_region_1and2['ElNino_OISST_region_1and2']['x']\n",
    "# plt.plot(ElNino_OISST_region_1and2_x,ElNino_OISST_region_1and2_y)\n",
    "# plt.show(\n",
    "# )\n",
    "ElNino_OISST_region_3_y=ElNino_OISST_region_3['ElNino_OISST_region_3']['y'].to_numpy()\n",
    "ElNino_OISST_region_3_x=ElNino_OISST_region_3['ElNino_OISST_region_3']['x']\n",
    "# plt.plot(ElNino_OISST_region_3_x,ElNino_OISST_region_3_y)\n",
    "# plt.show(\n",
    "# )\n",
    "\n",
    "ElNino_OISST_region_3and4_y=ElNino_OISST_region_3and4['ElNino_OISST_region_3and4']['y'].to_numpy()\n",
    "ElNino_OISST_region_3and4_x=ElNino_OISST_region_3and4['ElNino_OISST_region_3and4']['x']\n",
    "# plt.plot(ElNino_OISST_region_3and4_x,ElNino_OISST_region_3and4_y)\n",
    "# plt.show(\n",
    "# )\n",
    "\n",
    "\n",
    "ElNino_OISST_region_4_y=ElNino_OISST_region_4['ElNino_OISST_region_4']['y'].to_numpy()\n",
    "ElNino_OISST_region_4_x=ElNino_OISST_region_4['ElNino_OISST_region_4']['x']\n",
    "# plt.plot(ElNino_OISST_region_4_x,ElNino_OISST_region_4_y)\n",
    "# plt.show(\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points=np.arange(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=torch.tensor(ElNino_OISST_region_1and2_y).float().cuda()\n",
    "x1=torch.tensor(ElNino_OISST_region_3_y).float().cuda()\n",
    "x2=torch.tensor(ElNino_OISST_region_4_y).float().cuda()\n",
    "x3=torch.tensor(ElNino_OISST_region_3and4_y).float().cuda()\n",
    "x0=torch.t(x0)\n",
    "x1=torch.t(x1)\n",
    "x2=torch.t(x2)\n",
    "x3=torch.t(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = torch.tensor([0] * x0.shape[0] + [1] * x1.shape[0] + [2] * x2.shape[0] + [3] * x3.shape[0])\n",
    "X=torch.concatenate([x0,x1,x2,x3])\n",
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(X,labels,shuffle=True)\n",
    "x_train=x_train.reshape(111,1,12).cuda()\n",
    "y_train=y_train.unsqueeze(1).cuda()\n",
    "x_test=x_test.reshape(37,1,12).cuda()\n",
    "y_test=y_test.unsqueeze(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_17632\\1189248831.py:2: DeprecationWarning: The method 'evaluate' is deprecated. Please use the normal calling notation on the basis object instead.\n",
      "  basis.evaluate(eval_points=np.arange(12)).shape,fd(x_train[:,0,:].cpu()).to_basis(basis).coefficients.shape\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_17632\\1189248831.py:4: DeprecationWarning: The method 'evaluate' is deprecated. Please use the normal calling notation on the basis object instead.\n",
      "  basis_eval = basis.evaluate(np.arange(12))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 12])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis=B(knots=linspace(1,12,4),order=4)\n",
    "basis.evaluate(eval_points=np.arange(12)).shape,fd(x_train[:,0,:].cpu()).to_basis(basis).coefficients.shape\n",
    "\n",
    "basis_eval = basis.evaluate(np.arange(12))\n",
    "basis_fc = torch.from_numpy(basis_eval[:, :, 0]).float()\n",
    "\n",
    "basis_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 3)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 3)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Project_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Project_Classifier,self).__init__()\n",
    "    \n",
    "        self.flatten=nn.Sequential(\n",
    "            nn.Flatten(start_dim=1,end_dim=-1),\n",
    "\n",
    "        )\n",
    "        self.fc_block1=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(6,256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc_block2=nn.Sequential(\n",
    "        nn.Linear(256,512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )\n",
    "        self.fc_block3=nn.Sequential(\n",
    "        nn.Linear(512,32),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(32,4)\n",
    "        )\n",
    "    def Project(self,x,basis_fc):\n",
    "        f=torch.matmul(x,basis_fc)\n",
    "        return f\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        grid=fd(x[:,0,:].cpu(),grid_points=grid_points)\n",
    "        \n",
    "        features=self.Project(x[:,0,:],basis_fc=basis_fc)\n",
    "        flatten_out=self.flatten(features)\n",
    "        out1=self.fc_block1(flatten_out)\n",
    "        out2=self.fc_block2(out1)\n",
    "        out3=self.fc_block3(out2)\n",
    "        return out3.float().unsqueeze_(2).unsqueeze(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_17632\\43120078.py:1: DeprecationWarning: The method 'evaluate' is deprecated. Please use the normal calling notation on the basis object instead.\n",
      "  basis_fc=torch.t(torch.from_numpy(basis.evaluate(grid_points))[:,:,0]).float().cuda()\n"
     ]
    }
   ],
   "source": [
    "basis_fc=torch.t(torch.from_numpy(basis.evaluate(grid_points))[:,:,0]).float().cuda()\n",
    "project_Classifier=Project_Classifier().cuda().apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_adam=0.0001\n",
    "lr_sgd=0.001\n",
    "batch_size=32\n",
    "betas=[0.45,0.98]\n",
    "optimizer=optim.Adam(project_Classifier.parameters(),lr=lr_adam,betas=betas)\n",
    "# optimizer=optim.SGD(project_Classifier.parameters(),lr=lr_sgd)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "def train(n_epochs):\n",
    "    train_loss=torch.tensor(0).cuda().long()\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print(\"Précision moyenne =\",((torch.sum(torch.argmax(project_Classifier(x_test),dim=1).squeeze(1)==y_test)/37)*100).detach().cpu().numpy(),\"%\")  \n",
    "        for i in range(int(len(x_train)/batch_size)):\n",
    "            functions_train=x_train[batch_size*i:batch_size*(1+i),:,:]\n",
    "            labels_train=y_train[batch_size*i:batch_size*(1+i)]\n",
    "            optimizer.zero_grad()\n",
    "            output=project_Classifier(functions_train)\n",
    "            loss=loss_function(input=output,target=labels_train.unsqueeze(1).long())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.long()\n",
    "        return train_loss,loss \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision moyenne = 78.37838 %\n",
      "Précision moyenne = 78.37838 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(1000)\n",
    "print(\"Précision moyenne =\",((torch.sum(torch.argmax(project_Classifier(x_test),dim=1).squeeze(1)==y_test)/37)*100).detach().cpu().numpy(),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
