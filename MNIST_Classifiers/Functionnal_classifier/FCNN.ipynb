{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 15 14:49:58 2022\n",
    "\n",
    "@author: Sidi Wu and Cédric Beaulac\n",
    "\n",
    "Functional autoencoder implementation\n",
    "\"\"\"\n",
    "\n",
    "# Import modules\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "# import skfda as fda\n",
    "# from skfda import representation as representation\n",
    "# from skfda.exploratory.visualization import FPCAPlot\n",
    "# # from skfda.exploratory.visualization import FPCAPlot\n",
    "# # from skfda.preprocessing.dim_reduction import FPCA\n",
    "# # from skfda.representation.basis import BSpline, Fourier, Monomial\n",
    "import scipy\n",
    "from scipy.interpolate import BSpline\n",
    "import os\n",
    "import ignite\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from random import seed\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from statistics import stdev\n",
    "import skfda\n",
    "from skfda.representation import FDataGrid as fd\n",
    "from skfda.representation.basis import BSpline as bsp\n",
    "from skfda.representation.basis import FDataBasis as bsp_reconstruction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"sfts\". The constructor for class \"fts\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fts\". The constructor for class \"fds\" will be used instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\rdata\\conversion\\_conversion.py:843: UserWarning: Missing constructor for R class \"fds\". The underlying R object is returned instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Importation des données sous forme FDA\n",
    "\n",
    "ElNino_OISST_region_1and2=skfda.datasets.fetch_cran(\"ElNino_OISST_region_1and2\",\"rainbow\")\n",
    "ElNino_OISST_region_3=skfda.datasets.fetch_cran(\"ElNino_OISST_region_3\",\"rainbow\")\n",
    "ElNino_OISST_region_4=skfda.datasets.fetch_cran(\"ElNino_OISST_region_4\",\"rainbow\")\n",
    "ElNino_OISST_region_3and4=skfda.datasets.fetch_cran(\"ElNino_OISST_region_3and4\",\"rainbow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElNino_OISST_region_1and2_y=ElNino_OISST_region_1and2['ElNino_OISST_region_1and2']['y'].to_numpy()\n",
    "ElNino_OISST_region_1and2_x=ElNino_OISST_region_1and2['ElNino_OISST_region_1and2']['x']\n",
    "# plt.plot(ElNino_OISST_region_1and2_x,ElNino_OISST_region_1and2_y)\n",
    "# plt.show(\n",
    "# )\n",
    "ElNino_OISST_region_3_y=ElNino_OISST_region_3['ElNino_OISST_region_3']['y'].to_numpy()\n",
    "ElNino_OISST_region_3_x=ElNino_OISST_region_3['ElNino_OISST_region_3']['x']\n",
    "# plt.plot(ElNino_OISST_region_3_x,ElNino_OISST_region_3_y)\n",
    "# plt.show(\n",
    "\n",
    "# )\n",
    "ElNino_OISST_region_3and4_y=ElNino_OISST_region_3and4['ElNino_OISST_region_3and4']['y'].to_numpy()\n",
    "ElNino_OISST_region_3and4_x=ElNino_OISST_region_3and4['ElNino_OISST_region_3and4']['x']\n",
    "# plt.plot(ElNino_OISST_region_3and4_x,ElNino_OISST_region_3and4_y)\n",
    "# plt.show(\n",
    "# )\n",
    "\n",
    "\n",
    "ElNino_OISST_region_4_y=ElNino_OISST_region_4['ElNino_OISST_region_4']['y'].to_numpy()\n",
    "ElNino_OISST_region_4_x=ElNino_OISST_region_4['ElNino_OISST_region_4']['x']\n",
    "# plt.plot(ElNino_OISST_region_4_x,ElNino_OISST_region_4_y)\n",
    "# plt.show(\n",
    "# )\n",
    "grid_points=ElNino_OISST_region_1and2_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=torch.tensor(ElNino_OISST_region_1and2_y).float().cuda()\n",
    "x1=torch.tensor(ElNino_OISST_region_3_y).float().cuda()\n",
    "x2=torch.tensor(ElNino_OISST_region_4_y).float().cuda()\n",
    "x3=torch.tensor(ElNino_OISST_region_3and4_y).float().cuda()\n",
    "x0=torch.t(x0)\n",
    "x1=torch.t(x1)\n",
    "x2=torch.t(x2)\n",
    "x3=torch.t(x3)\n",
    "\n",
    "# train_index=np.random.permutation(torch.tensor(np.arange(30)))\n",
    "# labels = torch.tensor([0] * x0.shape[0] + [1] * x1.shape[0] + [2] * x2.shape[0] + [3] * x3.shape[0])\n",
    "# x0_train,y0_train=x0[train_index,:],labels[train_index]\n",
    "# x1_train,y1_train=x1[train_index,:],labels[train_index]\n",
    "# x2_train,y2_train=x2[train_index,:],labels[train_index]\n",
    "# x3_train,y3_train=x3[train_index,:],labels[train_index]\n",
    "# X=torch.concatenate([x0_train,x1_train,x2_train,x3_train],axis=0)\n",
    "# X_test=torch.concatenate([x0[~train_index],x1[~train_index],x2[~train_index],x3[~train_index]],axis=0)\n",
    "# Y_test=torch.tensor(labels[~train_index_long])\n",
    "# Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = torch.tensor([0] * x0.shape[0] + [1] * x1.shape[0] + [2] * x2.shape[0] + [3] * x3.shape[0])\n",
    "X=torch.concatenate([x0,x1,x2,x3])\n",
    "x_train,x_test,y_train,y_test=sklearn.model_selection.train_test_split(X,labels,shuffle=True)\n",
    "x_train=x_train.reshape(111,1,12).cuda()\n",
    "y_train=y_train.unsqueeze(1).cuda()\n",
    "x_test=x_test.reshape(37,1,12).cuda()\n",
    "y_test=y_test.unsqueeze(1).cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 3)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 3)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNN,self).__init__()\n",
    "        self.convlayer1=nn.Sequential(\n",
    "\n",
    "            nn.Conv1d(1,64,kernel_size=5,stride=1,padding=1,dilation=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.18),\n",
    "        )\n",
    "        \n",
    "        self.convlayer2=nn.Sequential(\n",
    "\n",
    "            nn.Conv1d(64,128,kernel_size=5,stride=1,padding=1,dilation=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.18),\n",
    "        )\n",
    "\n",
    "        self.fc_block=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*8,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.18),\n",
    "        \n",
    "            nn.Linear(128,4),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        Conv_out=self.convlayer1(x)\n",
    "        Conv_out2=self.convlayer2(Conv_out)\n",
    "        n_conv_out=Conv_out2.shape[1]\n",
    "        Lin_out=self.fc_block(Conv_out2)\n",
    "        return Lin_out.float().unsqueeze_(2).unsqueeze_(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([111, 1, 12]), torch.Size([111, 64, 10])]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_conv_out=10\n",
    "CNN=FCNN().cuda().apply(weights_init_normal)\n",
    "Conv_out=CNN.convlayer1(x_train)\n",
    "[x_train.shape,Conv_out.shape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.00001\n",
    "batch_size=32\n",
    "betas=[0.45,0.98]\n",
    "optimizer=optim.Adam(params=CNN.parameters(),lr=lr,betas=betas)\n",
    "\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "train_loss=torch.tensor(0).cuda().long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "def train(n_epochs):\n",
    "    train_loss=torch.tensor(0).cuda().long()\n",
    "    \n",
    "    for i in range(int(len(x_train)/batch_size)):\n",
    "        functions_train=x_train[batch_size*i:batch_size*(1+i),:,:]\n",
    "        labels_train=y_train[batch_size*i:batch_size*(1+i)]\n",
    "        optimizer.zero_grad()\n",
    "        output=CNN(functions_train)\n",
    "        loss=loss_function(input=output,target=labels_train.unsqueeze(1).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.long()\n",
    "    return train_loss,loss \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision moyenne = 89.189186 %\n"
     ]
    }
   ],
   "source": [
    "train(100)\n",
    "print(\"Précision moyenne =\",((torch.sum(torch.argmax(CNN(x_test),dim=1).squeeze(1)==y_test)/37)*100).detach().cpu().numpy(),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
