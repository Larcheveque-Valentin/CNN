{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torch import nn, optim\n",
    "import visdom\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_classifier\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "##Classifier pytorch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=100\n",
    "batch_size=64\n",
    "num_img_channel=1\n",
    "img_size=28\n",
    "sample_interval=64          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnist_Classifier,self).__init__()\n",
    "\n",
    "    \n",
    "        self.fc_block=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28,128,bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "            \n",
    "    def forward(self,img):\n",
    "        l2_value=self.fc_block(img)\n",
    "        l2_value=l2_value.unsqueeze_(dim=2).unsqueeze_(dim=3)\n",
    "        return l2_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7, 8,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=[1,28,28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist_Classifier(\n",
       "  (fc_block): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=False)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Mnist_Classifier()\n",
    "classifier.cuda()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Mnist:\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5,), (0.5,)),  # Remarquez que les paramètres sont des tuples à un élément seulement\n",
    "         transforms.Grayscale()\n",
    "         ])\n",
    "    output_dir = './data/mnist'\n",
    "    return datasets.MNIST(root=output_dir, train=True,\n",
    "                          transform=compose, download=True)\n",
    "\n",
    "\n",
    "mnist = mnist_data()\n",
    "train_indices = range(0, int(0.8 * len(mnist)))  # Utilisez les 80% premières images pour l'entraînement\n",
    "train_dataset = Subset(mnist, train_indices)\n",
    "\n",
    "\n",
    "\n",
    "batch_iterator = DataLoader(train_dataset, shuffle=True, batch_size=batch_size) # List, NCHW format.\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "test_indices = range(int(0.8 * len(mnist)), len(mnist))\n",
    "test_dataset = Subset(mnist, test_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "display_server=\"http://localhost\"\n",
    "display_port=8097\n",
    "try:\n",
    "    \n",
    "    vis = visdom.Visdom(server=display_server, port=display_port, raise_exceptions=True) # Create vis env.\n",
    "except ImportError:\n",
    "    vis = None\n",
    "else:\n",
    "    vis.close(None) # Clear all figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9, device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=random.randint(1,12000)\n",
    "vis.images(mnist.data[48000+K,:,:])\n",
    "images=mnist.data[test_indices,:,:].unsqueeze(1).cuda().float()\n",
    "classifier(images)[K,:,:,:].argmax()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "optimizer=optim.Adam(classifier.parameters(),lr=lr,betas=(b1,b2))\n",
    "loss_C=nn.CrossEntropyLoss()\n",
    "seed = Variable(Tensor(25, noise_dim, 1, 1).normal_(0, 1), requires_grad=False) # To track the progress of the GAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(n_epochs):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        for i, (batch, labels) in enumerate(batch_iterator):\n",
    "            \n",
    "            imgs = Variable(batch.type(Tensor), requires_grad=False)\n",
    "            \n",
    "        \n",
    "            labels = Variable(labels.type(Tensor), requires_grad=False)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = classifier(imgs)\n",
    "\n",
    "            loss = loss_C(output, labels.unsqueeze(1).unsqueeze(2).long() )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:11<00:59, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:23<00:46, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:34<00:34, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:46<00:23, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:57<00:11, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:09<00:00, 11.51s/it]\n"
     ]
    }
   ],
   "source": [
    "train(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=random.randint(1,12000)\n",
    "vis.images(mnist.data[48000+K,:,:])\n",
    "images=mnist.data[test_indices,:,:].unsqueeze(1).cuda().float()\n",
    "classifier(images)[K,:,:,:].argmax()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(82.3833, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=mnist.targets[48000:].unsqueeze(1).unsqueeze(2).cuda()   \n",
    "predicted=torch.argmax(classifier(images),dim=1)\n",
    "(torch.sum(labels==predicted)*100/12000)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
