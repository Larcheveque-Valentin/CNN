{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torch import nn, optim\n",
    "import argparse\n",
    "import matplotlib as plt \n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import visdom\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Subset\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "##Classifier_cifar pytorch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=100\n",
    "batch_size=60\n",
    "num_img_channel=3\n",
    "img_size=32\n",
    "sample_interval=64          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_cifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier_cifar,self).__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.conv_layer1=nn.Sequential(\n",
    "            nn.Conv2d(num_img_channel,3,kernel_size=[7,7],stride=1,padding=2,bias =False,dilation=1),\n",
    "        \n",
    "            \n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv_layer2=nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=[6,6],stride=1,padding=0,bias =False,dilation=1,),\n",
    "        \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        self.fc_block1= nn.Sequential(\n",
    "            \n",
    "            nn.Linear(16*25*25,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,img):\n",
    "        layer1_out=self.conv_layer1(img)\n",
    "        layer2_out=self.conv_layer2(layer1_out)\n",
    "        conv_out=layer2_out.view(img.size(0),16*25*25)\n",
    "        l2_value = self.fc_block1(conv_out)\n",
    "        l2_value2 = l2_value.unsqueeze_(dim=2).unsqueeze_(dim=3)\n",
    "        return l2_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des ensembles d'entraînement :\n",
      "x_train: torch.Size([50000, 32, 32, 3])\n",
      "y_train: torch.Size([50000, 1])\n",
      "Dimensions des ensembles de test :\n",
      "x_test: torch.Size([10000, 32, 32, 3])\n",
      "y_test: torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "# Téléchargement des données CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train_vis,x_test_vis=(x_train,x_test)\n",
    "(x_train, y_train), (x_test, y_test)= (torch.tensor(x_train),torch.tensor(y_train).cuda()), (torch.tensor(x_test),torch.tensor( y_test).cuda())\n",
    "# Affichage des dimensions des ensembles d'entraînement et de test\n",
    "print('Dimensions des ensembles d\\'entraînement :')\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('Dimensions des ensembles de test :')\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "x_train=x_train.permute(0,3,1,2).cuda().float()\n",
    "x_test=x_test.permute(0,3,1,2).cuda().float()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_cifar=Classifier_cifar()\n",
    "classifier_cifar=classifier_cifar.cuda()\n",
    "\n",
    "classifier_cifar.apply(weights_init_normal)\n",
    "def Class_out(K):\n",
    "    if classifier_cifar(x_test)[K].argmax()==0:\n",
    "        print(\"C'est un Avion!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==1:\n",
    "        print(\"C'est une Voiture!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==2:\n",
    "        print(\"C'est un Oiseau!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==3:\n",
    "        print(\"C'est un chat!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==4:\n",
    "        print(\"C'est un Cerf!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==5:\n",
    "        print(\"C'est un Chien!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==6:\n",
    "        print(\"C'est une Grenouille!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==7:\n",
    "        print(\"C'est un Cheval!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==8:\n",
    "        print(\"C'est un Bateau!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==9:\n",
    "        print(\"C'est un Camion!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 3, 30, 30]), torch.Size([1, 16, 25, 25])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image_conv1=classifier_cifar.conv_layer1(x_test[0,:,:,:].unsqueeze(0))\n",
    "Image_conv2=classifier_cifar.conv_layer2(Image_conv1)\n",
    "\n",
    "[Image_conv1.shape,Image_conv2.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 10, 1, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_cifar(x_test[:13,:,:,:]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(x_test_vis[1001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=random.randint(0,10000)\n",
    "Image_vis=x_test[K,:,:,:].unsqueeze(0)\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 16), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2952\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2953\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2954\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 16), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17072\\2969861863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Créez une image à partir du tableau NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_vis_conv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2953\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2955\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2956\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 16), |u1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.cpu().detach().numpy()\n",
    "Image_vis_conv2=Image_vis_conv2.cpu().detach().numpy()\n",
    "Image_vis_conv1=np.transpose(Image_vis_conv1,(0,2,3,1))\n",
    "Image_vis_conv2=np.transpose(Image_vis_conv2,(0,2,3,1))\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.squeeze(0)\n",
    "Image_vis_conv2=Image_vis_conv2.squeeze(0)\n",
    "\n",
    "# Créez une image à partir du tableau NumPy\n",
    "Image.fromarray(np.uint8(Image_vis_conv2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.00001\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "optimizer=optim.Adam(classifier_cifar.parameters(),lr=lr,betas=(b1,b2))\n",
    "loss_C=nn.CrossEntropyLoss()\n",
    "\n",
    "indice=np.arange(50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(n_epochs):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        shuffled_indices=np.random.permutation(indice)\n",
    "        x_train_shuffled=x_train[shuffled_indices,:,:,:]\n",
    "        y_train_shuffled=y_train[shuffled_indices]\n",
    "        for i in range(int(len(x_train)/batch_size)):\n",
    "            imgs= x_train_shuffled[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "            \n",
    "        \n",
    "            labels = y_train_shuffled[i*batch_size:(i+1)*batch_size]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = classifier_cifar(imgs)\n",
    "\n",
    "            loss = loss_C(output, labels.unsqueeze(1).long() )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:13,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:09<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:13<00:03,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3]],\n",
       "\n",
       "        [[9]],\n",
       "\n",
       "        [[8]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3]],\n",
       "\n",
       "        [[5]],\n",
       "\n",
       "        [[7]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(classifier_cifar(x_test),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est un Chien!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=random.randint(0,10000)\n",
    "Class_out(K)\n",
    "Image.fromarray(np.uint8(x_test_vis[K]))\n",
    "#Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAIAAAC0Ujn1AAAFjUlEQVR4nEWWS5IkxxFDHzw+mdXVPaRImrjRAXQG3f8OMq200UIbcjj9qarMiHBo0aSIAzyDAeZu0N/+ofvXff9WMYCCwHmc1LN9Ucm4ax54nc6kBxsRYiQ5cEgFspG72lJOzYBy/ftx+eeoL/+6fqvfHTn4nexapsncvNrwG7fH7vvkhHhqfdN8TE7kOG1FbBGSg6rvW9Z1vi9P/fKyPWf9z/Y+1l2zIzAuLjGTeT8535L/BmeipEPRWG+cprhVZZLpOBQ4r5o1jvOFhMvr0Xy/z8qnhABkKbuA9QFVlKxFs8MTIn0jgssu7NG4SHFnLUbkVhajzPP7+vTCDuYP9O+yIYleyGU6/FXxTds7/oXEDsXOQyhzNrKzTlm2FXDpVp7rvs0iYvyBNgYEC61c1bGjayu11cWcHjgb2r12cxAPqJrTTFvCseyyuNaHTq2lLMT/AwGQAvIYQ376Qc89xuO82epZr9YXU62b6imWuOGbVNAVlImyEPb1nu3wKvzpGhEgn9i1ocL47VgforBdVVFZzAfzUIqCE1PkF5QpKR2s/VX57NvltOr603UI5Umd8QLmccuP36w7qjodHOLOnLiSu3N3vKBn6rLfKFaPjUWu8yO4StuifjoukpjE5EnZWe++f4VT0W2LxeOBUxY0CK0NBXV6nlDk2heNPIO6lbbproMAJEkJJ5t9wYfvr/YDXVFXGSZt2ZhqCiQsxYEeYob3LSNkhZ4ve9eX+Z7WkRUIGZ/ZrGcx+HhznsRVdaM+nMMLaKhCyAXS3FmV9Vm912aXWPmU+0/n7ZhjUpIawrkkYifl4+b8kHbalTZI2d0NCgScRmkZywAtilnncndpcel4Oj5i/axbGzVEVjCrMg/P34TUL1Tby0uoqggZDfYAeQ5GoEKkeWgh76VY8ZbvrHspdSc7oYoKiac93mBKO5zMB2vCIlOaoSFbFGlDm6PRCmFP0qY6s7/e5+NQ6GltoiSVQGkvxrJnUWslBjcvIQHCHpktXBoEAbVLJpO5iEBYc2UFVpt4K4UlVC1XOA1TXByjl8U0aShiIskTdxp8FsdiTcbCiRoIixFUVFcOKQVQE8pmv0qPqJvTZx49uxjGsPDCAYtxxwmBgzQYN1TgACuxyT7IzM9biZUaTbUrHk0juJBrsJoKsgkIIwxzsNLrJE80pUOS2a0O9GKMGNSVnz8pND2mylPtyjmCS+3dPIaH1KCCReAJhyy5YZdElrbozxFtYgcZ6zM/kMGuSun0Krq8QI2799NCiSVQxQ8QFGEkWXZmPD2Xp3Vs49xxNyjBlTFVBQGiKokP1We3q8i8jVsOSkg7ZQGEGIgCskENRbYX+hedYnyAEYSpFaYzGeGss1KMpKGxe74qHjEdblInB2nT4YAgNjUr1Gt3zWN887AoIhra3A7CQDnxRFAdGlVjFH1oHuqPWrr9hEScTLQSVpSjxJW2+Shx/vq0f7wUv0+TDf84lBevbYiAfoozx3BNcAYjztEprT3nrrPuaqfnaSY0UKsu7qcqX+D+03h7s1fRtl7My93VmvOipixeg37GOkclKWsRy5t60+YVrLfgnM4Ky6DyJbdX+V6ijks+6OIvmrPFUc5zlqqyZx5ByC8cI6u5kKHEAVn2Uq/b2GMlsabzBqfkYF3i2OxzOmbZ761EHhdGu9J/pFzimC17xCXt5CYtNVifY8ErIrtmDGu28/1jjKMSwR7cNlYrGsH2hEaWY7TqLJOani+h71Z+Zc1La7Ud85yekNNP16z7/jI1/FXTzA9KbSu7s9OrmLqn3PC26mr68PtcEVmJVdqdnTX22q/5eKTG9ty7jnkkb8/5w64a/369P2+sB5iBmj0kidV52FoOHjXZ/X5axkVMEKQY1iQsSbMV9am0hJOfQ/8DBg4BhM5YcFUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=30x30>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image_vis=x_test[K,:,:,:].unsqueeze(0)\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.cpu().detach().numpy()\n",
    "Image_vis_conv2=Image_vis_conv2.cpu().detach().numpy()\n",
    "\n",
    "Image_vis_conv1=np.transpose(Image_vis_conv1,(0,2,3,1))\n",
    "Image_vis_conv2=np.transpose(Image_vis_conv2,(0,2,3,1))\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.squeeze(0)\n",
    "Image_vis_conv2=Image_vis_conv2.squeeze(0)\n",
    "\n",
    "# Créez une image à partir du tableau NumPy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image.fromarray(np.uint8(Image_vis_conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=16x625>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(np.concatenate(Image_vis_conv2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision moyenne= 59.35 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy=(torch.sum(torch.argmax(classifier_cifar(x_test),dim=1).squeeze(1)==y_test))*100/10000\n",
    "print('Précision moyenne=', np.array((accuracy.float().cpu())),\"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
