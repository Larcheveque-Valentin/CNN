{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torch import nn, optim\n",
    "import argparse\n",
    "import matplotlib as plt \n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import visdom\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Subset\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "##Classifier_cifar pytorch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=100\n",
    "batch_size=60\n",
    "num_img_channel=3\n",
    "img_size=32\n",
    "sample_interval=64          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_cifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier_cifar,self).__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.conv_layer1=nn.Sequential(\n",
    "            nn.Conv2d(num_img_channel,3,kernel_size=[7,7],stride=1,padding=2,bias =False,dilation=1),\n",
    "        \n",
    "            \n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv_layer2=nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=[6,6],stride=1,padding=0,bias =False,dilation=1,),\n",
    "        \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        self.fc_block1= nn.Sequential(\n",
    "            \n",
    "            nn.Linear(16*25*25,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,img):\n",
    "        layer1_out=self.conv_layer1(img)\n",
    "        layer2_out=self.conv_layer2(layer1_out)\n",
    "        conv_out=layer2_out.view(img.size(0),16*25*25)\n",
    "        l2_value = self.fc_block1(conv_out)\n",
    "        l2_value2 = l2_value.unsqueeze_(dim=2).unsqueeze_(dim=3)\n",
    "        return l2_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des ensembles d'entraînement :\n",
      "x_train: torch.Size([50000, 32, 32, 3])\n",
      "y_train: torch.Size([50000, 1])\n",
      "Dimensions des ensembles de test :\n",
      "x_test: torch.Size([10000, 32, 32, 3])\n",
      "y_test: torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "# Téléchargement des données CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train_vis,x_test_vis=(x_train,x_test)\n",
    "(x_train, y_train), (x_test, y_test)= (torch.tensor(x_train),torch.tensor(y_train).cuda()), (torch.tensor(x_test),torch.tensor( y_test).cuda())\n",
    "# Affichage des dimensions des ensembles d'entraînement et de test\n",
    "print('Dimensions des ensembles d\\'entraînement :')\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('Dimensions des ensembles de test :')\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "x_train=x_train.permute(0,3,1,2).cuda().float()\n",
    "x_test=x_test.permute(0,3,1,2).cuda().float()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_cifar=Classifier_cifar()\n",
    "classifier_cifar=classifier_cifar.cuda()\n",
    "\n",
    "classifier_cifar.apply(weights_init_normal)\n",
    "def Class_out(K):\n",
    "    if classifier_cifar(x_test)[K].argmax()==0:\n",
    "        print(\"C'est un Avion!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==1:\n",
    "        print(\"C'est une Voiture!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==2:\n",
    "        print(\"C'est un Oiseau!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==3:\n",
    "        print(\"C'est un chat!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==4:\n",
    "        print(\"C'est un Cerf!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==5:\n",
    "        print(\"C'est un Chien!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==6:\n",
    "        print(\"C'est une Grenouille!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==7:\n",
    "        print(\"C'est un Cheval!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==8:\n",
    "        print(\"C'est un Bateau!\")\n",
    "    if classifier_cifar(x_test)[K].argmax()==9:\n",
    "        print(\"C'est un Camion!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 3, 30, 30]), torch.Size([1, 16, 25, 25])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image_conv1=classifier_cifar.conv_layer1(x_test[0,:,:,:].unsqueeze(0))\n",
    "Image_conv2=classifier_cifar.conv_layer2(Image_conv1)\n",
    "\n",
    "[Image_conv1.shape,Image_conv2.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 10, 1, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_cifar(x_test[:13,:,:,:]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(x_test_vis[1001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=random.randint(0,10000)\n",
    "Image_vis=x_test[K,:,:,:].unsqueeze(0)\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 16), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2952\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2953\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2954\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 16), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17072\\2969861863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Créez une image à partir du tableau NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_vis_conv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2953\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2955\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2956\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 16), |u1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.cpu().detach().numpy()\n",
    "Image_vis_conv2=Image_vis_conv2.cpu().detach().numpy()\n",
    "Image_vis_conv1=np.transpose(Image_vis_conv1,(0,2,3,1))\n",
    "Image_vis_conv2=np.transpose(Image_vis_conv2,(0,2,3,1))\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.squeeze(0)\n",
    "Image_vis_conv2=Image_vis_conv2.squeeze(0)\n",
    "\n",
    "# Créez une image à partir du tableau NumPy\n",
    "Image.fromarray(np.uint8(np.concatenate(Image_vis_conv2)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.00001\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "optimizer=optim.Adam(classifier_cifar.parameters(),lr=lr,betas=(b1,b2))\n",
    "loss_C=nn.CrossEntropyLoss()\n",
    "\n",
    "indice=np.arange(50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(n_epochs):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        shuffled_indices=np.random.permutation(indice)\n",
    "        x_train_shuffled=x_train[shuffled_indices,:,:,:]\n",
    "        y_train_shuffled=y_train[shuffled_indices]\n",
    "        for i in range(int(len(x_train)/batch_size)):\n",
    "            imgs= x_train_shuffled[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "            \n",
    "        \n",
    "            labels = y_train_shuffled[i*batch_size:(i+1)*batch_size]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = classifier_cifar(imgs)\n",
    "\n",
    "            loss = loss_C(output, labels.unsqueeze(1).long() )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:13,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:09<00:06,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:13<00:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3]],\n",
       "\n",
       "        [[9]],\n",
       "\n",
       "        [[8]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3]],\n",
       "\n",
       "        [[5]],\n",
       "\n",
       "        [[7]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(classifier_cifar(x_test),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est une Grenouille!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=random.randint(0,10000)\n",
    "Class_out(K)\n",
    "Image.fromarray(np.uint8(x_test_vis[K]))\n",
    "#Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAIAAAC0Ujn1AAAFWklEQVR4nD3WwY4cSY6E4d9IekRmlST0zOz7v94Ce+iG1KrKzHB32h6qd3nkhYCB4EdVsTc+qCIWBG6YOM2SjQOdjK0Ib+HwfgihhE1vIxEggF7kyDHQ5y4aO3lps5muYhVaGJH2UnfFpleX3GKnOhyFJYFK3mBoaBLc242S2gAN9mIJmgAb2hS5aHa3r4MpPIlFbJ1BB7Ptkwpt44UhGvfXIIcBDLC/WhU73N4BhQdgGopDKadL+6i5WfQobpZe3rYTFQQyYTII/q9MkKMVz9XrVJ2KVWxkhhR3ovfIfTsprZYzI0ptd5PysLPppAsnr03QIJBEaab3xOSPuB+553bxHtzbNbGby0SPd+sNDnbQD4D7iDHx6t6WaIEpBCU8mBtdGvy4kUfrlwf4hzPVT/bymnqDeCk08pxr+fHg/kaMmJOXXdK9WeG1iaJIocFsvKt0+y6y1+rtHoqR0S/8i0yuZp7ESb+mH5xY0v2mWbCajEx0eS/ytJaKJcqiRrj/ax/37D/9/BAlSs+PbO2urtJtaJW9TLOSsEoCj1/iFesbPvz4i2ydcuMCw8zSLX4oHp+Pz9cnic5ibK7fa0L/QX1j/mRfHCfjpTr1GPYDv9jmbg5suN3Vy49NisDmGPxnL3/k/+TbJYXXjc9/8fPdKt/Uxwf3X7z/dr7EPR5vflTHcKg3UGyQOYrzRpy4ia0C/DnyOOr8/ev6WCNu/27/7Pnfue/fdftAZvj3bx1yH9YlJD34PvUsnp9wJ2E+Q2/uSb6U6VdTaMhP4vn3GffvLPL5sw7PZmnmqJNXt/MKX1LeiIf7mRw9xfMCrME8WSgb/02a/IGhYOFhX7irdX7v519B38+49rCS6+baOgd6clzO9t/nXt95udNicrT61vHT15AxwV18M9LAM91JXIIfg593dh/5Oo45z3zNzeuk7ujlWRrbe1Gn4sUR8VEd035X/OmFukg7/uV8SAoZu7FBnPhEv/+jrYw/U4fP51wu3uZ+4nFkRn9epOK2A3Ti9lrwSZSpGMtxp1+UZYQaizaXdJhv+PxjzaP9vTlDzCrHwf0V8eaWueODMcmWH1qr2/GmCPgETQ4TBGny65AURpN4cOZPqTeTIxkxhuk/3O87wlE6zVsTl/bsx/YRUsb2fi4PqQ76IpC22IEgGh22YqlfznpV/iavXu+7EdZG41LmEFL6YxLQKS/YvVIH5Pa2olzYgETBNDKMxQFHrCtZW09/D7m5ruwMLrrmrBqId18T3Ds4m5p5P/Wxuz8MKhZAnrjBsAmTt6wf+zHaRG5Otay6dNEKzvaWeIgvRJcqsypX7L8+ISXBojAkOwj9Q5xBn/tMuki6D/1Ux9ONsawUYo3JZvaZVbkn/hilhwFvFbpO/sFYRb5YQH4BqtvhTBx8Cm/rCS0Lj9I+0it0daKb90tMENFuqe/EokAq3CAE3oBIsdqSKk73q7GC3jIKfAvCerrCu4hmvSRjQUBZgUPHdP2/jP4HSrdsgWVZJjC1GWYo3qnuedEbSWn2C4yFD5QkHBczsdHXFfla7EJebJk0C0sY0Ry6lTTz2nt3QCQSe432NIgjx3Bd/YQSbGwHCUaBOlreh2WRRUiNAiJGqQeeFfsrvt01171pJAlqOsSGEAW9vcvBG1IwSu2eWUMZybpxnENxRp06uGoHF9s6yNTwKO4mVPIhZUQGJXKMjEbWrRTfzlu8VW5/JTbIQ5v9pNW3yh/keXlxu6pi4Rnxdh5nWG5YmM68RRwsN4cdDZYOVMfz8bF1wzrltV840R2DmMoJwWZ+TOuub3d3xQXIvXyICH29NSEDHZx/6Jr8bf8vmrHCh3aZ6f4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=30x30>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image_vis=x_test[K,:,:,:].unsqueeze(0)\n",
    "Image_vis_conv1=classifier_cifar.conv_layer1(Image_vis)\n",
    "Image_vis_conv2=classifier_cifar.conv_layer2(Image_vis_conv1)\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.cpu().detach().numpy()\n",
    "Image_vis_conv2=Image_vis_conv2.cpu().detach().numpy()\n",
    "\n",
    "Image_vis_conv1=np.transpose(Image_vis_conv1,(0,2,3,1))\n",
    "Image_vis_conv2=np.transpose(Image_vis_conv2,(0,2,3,1))\n",
    "\n",
    "Image_vis_conv1=Image_vis_conv1.squeeze(0)\n",
    "Image_vis_conv2=Image_vis_conv2.squeeze(0)\n",
    "\n",
    "# Créez une image à partir du tableau NumPy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image.fromarray(np.uint8(Image_vis_conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAJxCAAAAABur21rAAAFi0lEQVR4nK1aSbbjMAikyO/73zjuhTVAUcj+/ZpFYssIMRayErM3hHjjzSM04y8JMHgUjvujW2BOKosyG5aM+8sr477Kxr0kKGN/7QDpQKhHJ5oGwLA+SD6SOPKCjiKyjZlzMZ20zA+h5rvxSFh/TfJ+ml54XbkVHU7sIQLEejS0CPS6Wva5sFuqVJMd/OguIpJDHvt08ofM+kynC48dJ7oeriwiZSU7clzcrlaxEwUO5/GSCq9k3fCy6tbtgtmlRMQRBapuUdQOsvP04K6t9+/x54FolXLdVEUKYXTpTkuoGtaJNuqlNy6v1LkC7MQGZ89BI/rDLB6+lKSQvqRu9khxIVgcghBNCJPOLdX28tvfGIYI3ytVzkzpxmN3+TG3r9lluBYriypmNg3Ag4ysmo9P6i74VDzw4Deq7PVF8r3fIjl4ClvnxTmZaZpAI9UFMhd2b0CvpCI3d7PQO/7sJ/fsJghkze3Tnz1VZ8v2whJ7RbbSwgywj+3YBql+S8ONwuzLUknpWTMsGsOomuwFr+nbrZc188qFO2QO2G3/NUozo0ME1SA3eCU/uwv8EiCN6eUNBlZ8wsbFoVk5sSkFnhpDE7VTqAC1Q80aJiJok6Z5ZRYuT3dlCYvwFF9cEPLQzcwu+9GFChtIB7tuR103AgaZ+F4eLB1P5uoKDEUnXtA0Pj3xz9LcQULGWUaptg5sNK9k5zWR+KOErSFqT1Hl9KSpzaW6yKBpXCoTXyH5WMpxTBfNPeUKZNbQzD65OQTpSrVdVGv5nXvjInXYXLdL9hQSXSTKGzuGSJ8+E4F9vC2IAc0bGCxV2Tq+ASdiNqxAsWsvUw9ZG333W9GtzdxJDrPCRIcBvtntMgO+lj3TkoDtHGwsP43bdtMXJLJ3oPe25DWitadYX6J76Noqmjtz0XjQA018SA5DxOopadOfX/qqxrAcuU9++wvLCLioaq2HXkZjasvMcIuJBZoSePKixe9dwjWg63nbixudLhbcQ/Z5fKXMh7kOF/tWrz4CnrYk96Y8dpftvR2IcRVe6Qvme2QU6TNi6zTw3bt48MQG2PLiaa9QtBqjXNprlcaJ0NPevKN+pu+mpddkKAdlc5Fry4WR7xrkIL2rfaB8H+Ocj6gNDYyUoX3xoQ6FB7zT4VOmqJSwFixwG3YKFCtxgGwZskEzctCwVCTC4qb59CJhNl976AgpeT9m9PBDep1wg32L+XJvc1YlKvUwW+/EQTFqyvS45O+494GqUHLXnKL1CPWupRh1QgohPdzNUkbR1IuTnlVY1GDHA92lsAqiKZ1+8dO5OiPJJn+aWqVMyBE4/TlrWrFiJ8qHOXckB7aDhVNm0BxacMwg3zoffP/gOrkr6iwj1LqyaP+27hebd1aNgaaiymnt6Hexar4oyFn1vUf3S3SvcXW7VDiXh25GWe3M0TWOhHHt67zsPW+x+Im66j03yEI/LFWn42w4xABl4QmUvDjrGcHCG5yot6HBw7GUppUkIRV3pr/qYu9A+200FssJhjwVo8AsyuxxgBXkFl+efntI0jm7hNIHeCpX1Mc4mwqyrFNmCvc/RV8rlwUOuwRURffnRrI4YHGHnDBjS0i/FdxDVxwAH4tnzdYd7zCaMChcDNprKogM7oxXEXug/wKBWkg4DG9RWR0Up3+hYBwKD9L+X8ytYk2tqGGQyo2mvILzMVb6FebmfdjcpqrUPaV1JI2h2hRItVsLDhSrqIOymrqrB7/Wt9SHcP26cfnkIYWlCiA0UAxvqQe89NL9SmLLtLJQHYY+XLfm6NwZn9vZKV0WNqVcafZ8D4s+Wcs3vwMryc0ZPjNW/iHgpB/KiUvi5x8aTvLicD7XFyEok8M5AP1OCNMH3KfgvHBxxxLa2anrSVEFmJG/zczsL3SfNiRo6ATtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=16x625>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(np.concatenate(Image_vis_conv2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision moyenne= 59.3 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy=(torch.sum(torch.argmax(classifier_cifar(x_test),dim=1).squeeze(1)==y_test))*100/10000\n",
    "print('Précision moyenne=', np.array((accuracy.float().cpu())),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
