{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torch import nn, optim\n",
    "import argparse\n",
    "import visdom\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import gan_pytorch\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "\n",
    "##Classifier pytorch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=100\n",
    "batch_size=64\n",
    "num_img_channel=1\n",
    "img_size=28\n",
    "sample_interval=64          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "\n",
    "        def convlayer(n_input,n_output,k_size=4,stride=2, padding=2, normalize=True,dilatation=1):\n",
    "            block=[nn.Conv2d(n_input,n_output,kernel_size=k_size,stride=stride,padding=padding,bias =False,dilation=dilatation),]\n",
    "\n",
    "            if normalize:\n",
    "                block.append(nn.BatchNorm2d(n_output))\n",
    "            block.append(nn.LeakyReLU(0.18,inplace=True))\n",
    "            return block\n",
    "        \n",
    "        self.conv_block=nn.Sequential(\n",
    "            *convlayer(num_img_channel, 32,5,2,2,normalize=True),   \n",
    "            *convlayer(32,64,5,2,2),\n",
    "        )\n",
    "        self.fc_block= nn.Sequential(\n",
    "            nn.Linear(64*7*7,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.18,inplace=True),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "\n",
    "    def forward(self,img):\n",
    "        conv_out=self.conv_block(img)\n",
    "        conv_out=conv_out.view(img.size(0),64*7*7)\n",
    "        l2_value = self.fc_block(conv_out)\n",
    "        l2_value = l2_value.unsqueeze_(dim=2).unsqueeze_(dim=3)\n",
    "        return l2_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Mnist:\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5,), (0.5,)),  # Remarquez que les paramètres sont des tuples à un élément seulement\n",
    "         transforms.Grayscale()\n",
    "         ])\n",
    "    output_dir = './data/mnist'\n",
    "    return datasets.MNIST(root=output_dir, train=True,\n",
    "                          transform=compose, download=True)\n",
    "\n",
    "\n",
    "mnist = mnist_data()\n",
    "train_indices = range(0, int(0.8 * len(mnist)))  # Utilisez les 80% premières images pour l'entraînement\n",
    "train_dataset = Subset(mnist, train_indices)\n",
    "\n",
    "\n",
    "\n",
    "batch_iterator = DataLoader(train_dataset, shuffle=True, batch_size=batch_size) # List, NCHW format.\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv_block): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.18, inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.18, inplace=True)\n",
       "  )\n",
       "  (fc_block): Sequential(\n",
       "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.18, inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Classifier()\n",
    "classifier=classifier.cuda()\n",
    "\n",
    "classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "display_server=\"http://localhost\"\n",
    "display_port=8097\n",
    "try:\n",
    "    \n",
    "    vis = visdom.Visdom(server=display_server, port=display_port, raise_exceptions=True) # Create vis env.\n",
    "except ImportError:\n",
    "    vis = None\n",
    "else:\n",
    "    vis.close(None) # Clear all figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "optimizer=optim.Adam(classifier.parameters(),lr=lr,betas=(b1,b2))\n",
    "loss_C=nn.CrossEntropyLoss()\n",
    "seed = Variable(Tensor(25, noise_dim, 1, 1).normal_(0, 1), requires_grad=False) # To track the progress of the GAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(n_epochs):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        for i, (batch, labels) in enumerate(batch_iterator):\n",
    "            \n",
    "            imgs = Variable(batch.type(Tensor), requires_grad=False)\n",
    "            \n",
    "        \n",
    "            labels = Variable(labels.type(Tensor), requires_grad=False)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = classifier(imgs)\n",
    "\n",
    "            loss = loss_C(output, labels.unsqueeze(1).unsqueeze(2).long() )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:17<00:34, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:29<00:14, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:41<00:00, 13.92s/it]\n"
     ]
    }
   ],
   "source": [
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = range(int(0.8 * len(mnist)), len(mnist))\n",
    "test_dataset = Subset(mnist, test_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=random.randint(1,12000)\n",
    "vis.images(mnist.data[48000+K,:,:])\n",
    "images=mnist.data[test_indices,:,:].unsqueeze(1).cuda().float()\n",
    "classifier(images)[K,:,:,:].argmax()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.4000, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=mnist.targets[48000:].unsqueeze(1).unsqueeze(2).cuda()   \n",
    "predicted=torch.argmax(classifier(images),dim=1)\n",
    "(torch.sum(labels==predicted)*100/12000)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66168a667a11ac16aca0d0d9742c8419f93457ff66115bf85239ea370d417636"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
